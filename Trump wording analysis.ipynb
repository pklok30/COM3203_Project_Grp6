{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analysis of Trump's tweets\n",
    "\n",
    "Stylometry: to find out the style of writing or frequency of words from Mr. Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>comments</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake</td>\n",
       "      <td>1326926226888544256</td>\n",
       "      <td>2020-11-12 16:34:00+00:00</td>\n",
       "      <td>“REPORT: DOMINION DELETED 2.7 MILLION TRUMP VO...</td>\n",
       "      <td>17300000.0</td>\n",
       "      <td>24700000.0</td>\n",
       "      <td>61900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake</td>\n",
       "      <td>1326920264203046915</td>\n",
       "      <td>2020-11-12 16:10:18+00:00</td>\n",
       "      <td>.@FoxNews daytime ratings have completely coll...</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>8600000.0</td>\n",
       "      <td>34800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake</td>\n",
       "      <td>1326884956749127680</td>\n",
       "      <td>2020-11-12 13:50:00+00:00</td>\n",
       "      <td>“OK, I’ve seen enough. What’s going to happen ...</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>31800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>1326679385966047236</td>\n",
       "      <td>2020-11-12 00:13:08+00:00</td>\n",
       "      <td>Nobody wants to report that Pennsylvania and M...</td>\n",
       "      <td>8900000.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>41000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326673766915641345</td>\n",
       "      <td>2020-11-11 23:50:49+00:00</td>\n",
       "      <td>I am pleased to announce that I have given my ...</td>\n",
       "      <td>4100000.0</td>\n",
       "      <td>7100000.0</td>\n",
       "      <td>35800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fake</td>\n",
       "      <td>1326673298692972544</td>\n",
       "      <td>2020-11-11 23:48:57+00:00</td>\n",
       "      <td>Everyone is asking why the recent presidential...</td>\n",
       "      <td>5800000.0</td>\n",
       "      <td>8600000.0</td>\n",
       "      <td>49300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326525851752656898</td>\n",
       "      <td>2020-11-11 14:03:03+00:00</td>\n",
       "      <td>A guy named Al Schmidt, a Philadelphia Commiss...</td>\n",
       "      <td>6700000.0</td>\n",
       "      <td>7400000.0</td>\n",
       "      <td>33400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fake</td>\n",
       "      <td>1326519025552265216</td>\n",
       "      <td>2020-11-11 13:35:55+00:00</td>\n",
       "      <td>The Fake Pollsters at @ABC/@washingtonpost pro...</td>\n",
       "      <td>3800000.0</td>\n",
       "      <td>6900000.0</td>\n",
       "      <td>29800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326342742801326083</td>\n",
       "      <td>2020-11-11 01:55:26+00:00</td>\n",
       "      <td>Andrew McCabe was exposed for who he is today ...</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>6600000.0</td>\n",
       "      <td>29200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fake</td>\n",
       "      <td>1326327582074220544</td>\n",
       "      <td>2020-11-11 00:55:12+00:00</td>\n",
       "      <td>“I don’t care what state you’re in, this compu...</td>\n",
       "      <td>4800000.0</td>\n",
       "      <td>9200000.0</td>\n",
       "      <td>39900000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                   id                       date  \\\n",
       "0  fake  1326926226888544256  2020-11-12 16:34:00+00:00   \n",
       "1  fake  1326920264203046915  2020-11-12 16:10:18+00:00   \n",
       "2  fake  1326884956749127680  2020-11-12 13:50:00+00:00   \n",
       "3  fake  1326679385966047236  2020-11-12 00:13:08+00:00   \n",
       "4  fact  1326673766915641345  2020-11-11 23:50:49+00:00   \n",
       "5  fake  1326673298692972544  2020-11-11 23:48:57+00:00   \n",
       "6  fact  1326525851752656898  2020-11-11 14:03:03+00:00   \n",
       "7  fake  1326519025552265216  2020-11-11 13:35:55+00:00   \n",
       "8  fact  1326342742801326083  2020-11-11 01:55:26+00:00   \n",
       "9  fake  1326327582074220544  2020-11-11 00:55:12+00:00   \n",
       "\n",
       "                                               tweet    comments    retweets  \\\n",
       "0  “REPORT: DOMINION DELETED 2.7 MILLION TRUMP VO...  17300000.0  24700000.0   \n",
       "1  .@FoxNews daytime ratings have completely coll...   9000000.0   8600000.0   \n",
       "2  “OK, I’ve seen enough. What’s going to happen ...   3600000.0   8000000.0   \n",
       "3  Nobody wants to report that Pennsylvania and M...   8900000.0   1600000.0   \n",
       "4  I am pleased to announce that I have given my ...   4100000.0   7100000.0   \n",
       "5  Everyone is asking why the recent presidential...   5800000.0   8600000.0   \n",
       "6  A guy named Al Schmidt, a Philadelphia Commiss...   6700000.0   7400000.0   \n",
       "7  The Fake Pollsters at @ABC/@washingtonpost pro...   3800000.0   6900000.0   \n",
       "8  Andrew McCabe was exposed for who he is today ...   2000000.0   6600000.0   \n",
       "9  “I don’t care what state you’re in, this compu...   4800000.0   9200000.0   \n",
       "\n",
       "        likes  \n",
       "0  61900000.0  \n",
       "1  34800000.0  \n",
       "2  31800000.0  \n",
       "3  41000000.0  \n",
       "4  35800000.0  \n",
       "5  49300000.0  \n",
       "6  33400000.0  \n",
       "7  29800000.0  \n",
       "8  29200000.0  \n",
       "9  39900000.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data file we scraped from Donald Trump's twitter account\n",
    "df = pd.read_csv('Trump(processed).csv', encoding='utf8')\n",
    "#display the first ten row\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame for the tweets\n",
    "df_Trumptweets = pd.DataFrame(df['tweet'], columns=[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“REPORT: DOMINION DELETED 2.7 MILLION TRUMP VO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.@FoxNews daytime ratings have completely coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“OK, I’ve seen enough. What’s going to happen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nobody wants to report that Pennsylvania and M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am pleased to announce that I have given my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Everyone is asking why the recent presidential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A guy named Al Schmidt, a Philadelphia Commiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Fake Pollsters at @ABC/@washingtonpost pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Andrew McCabe was exposed for who he is today ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“I don’t care what state you’re in, this compu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  “REPORT: DOMINION DELETED 2.7 MILLION TRUMP VO...\n",
       "1  .@FoxNews daytime ratings have completely coll...\n",
       "2  “OK, I’ve seen enough. What’s going to happen ...\n",
       "3  Nobody wants to report that Pennsylvania and M...\n",
       "4  I am pleased to announce that I have given my ...\n",
       "5  Everyone is asking why the recent presidential...\n",
       "6  A guy named Al Schmidt, a Philadelphia Commiss...\n",
       "7  The Fake Pollsters at @ABC/@washingtonpost pro...\n",
       "8  Andrew McCabe was exposed for who he is today ...\n",
       "9  “I don’t care what state you’re in, this compu..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the first ten row\n",
    "df_Trumptweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“REPORT: DOMINION DELETED 2.7 MILLION TRUMP VO...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.@FoxNews daytime ratings have completely coll...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“OK, I’ve seen enough. What’s going to happen ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nobody wants to report that Pennsylvania and M...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am pleased to announce that I have given my ...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Everyone is asking why the recent presidential...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A guy named Al Schmidt, a Philadelphia Commiss...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Fake Pollsters at @ABC/@washingtonpost pro...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Andrew McCabe was exposed for who he is today ...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“I don’t care what state you’re in, this compu...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  word_count\n",
       "0  “REPORT: DOMINION DELETED 2.7 MILLION TRUMP VO...          38\n",
       "1  .@FoxNews daytime ratings have completely coll...          43\n",
       "2  “OK, I’ve seen enough. What’s going to happen ...          30\n",
       "3  Nobody wants to report that Pennsylvania and M...          45\n",
       "4  I am pleased to announce that I have given my ...          45\n",
       "5  Everyone is asking why the recent presidential...          27\n",
       "6  A guy named Al Schmidt, a Philadelphia Commiss...          49\n",
       "7  The Fake Pollsters at @ABC/@washingtonpost pro...          46\n",
       "8  Andrew McCabe was exposed for who he is today ...          52\n",
       "9  “I don’t care what state you’re in, this compu...          28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Trumptweets['word_count'] = df_Trumptweets['tweet'].apply(lambda x: len(str(x).split(\" \")))\n",
    "# count the word for each column\n",
    "df_Trumptweets[['tweet', 'word_count']].head(10)\n",
    "#[['titles', 'word_count']] is used to set the format of the table, the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing empty values if any\n",
    "df_Trumptweets['tweet'] = df_Trumptweets['tweet'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    “report: dominion deleted 2.7 million trump vo...\n",
       "1    .@foxnews daytime ratings have completely coll...\n",
       "2    “ok, i’ve seen enough. what’s going to happen ...\n",
       "3    nobody wants to report that pennsylvania and m...\n",
       "4    i am pleased to announce that i have given my ...\n",
       "5    everyone is asking why the recent presidential...\n",
       "6    a guy named al schmidt, a philadelphia commiss...\n",
       "7    the fake pollsters at @abc/@washingtonpost pro...\n",
       "8    andrew mccabe was exposed for who he is today ...\n",
       "9    “i don’t care what state you’re in, this compu...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the title, turn every word into lower case and join them together\n",
    "df_Trumptweets['tweet'] = df_Trumptweets['tweet'].apply(\n",
    "    lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "#display the first ten row\n",
    "df_Trumptweets['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    report dominion deleted 27 million trump votes...\n",
       "1    foxnews daytime ratings have completely collap...\n",
       "2    ok ive seen enough whats going to happen to th...\n",
       "3    nobody wants to report that pennsylvania and m...\n",
       "4    i am pleased to announce that i have given my ...\n",
       "5    everyone is asking why the recent presidential...\n",
       "6    a guy named al schmidt a philadelphia commissi...\n",
       "7    the fake pollsters at abcwashingtonpost produc...\n",
       "8    andrew mccabe was exposed for who he is today ...\n",
       "9    i dont care what state youre in this computer ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing punctuations\n",
    "df_Trumptweets['tweet'] = df_Trumptweets['tweet'].str.replace('[^\\w\\s]', '')\n",
    "df_Trumptweets['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#import the stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop\n",
    "#A list to know what are stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    report dominion deleted 27 million trump votes...\n",
       "1    foxnews daytime ratings completely collapsed w...\n",
       "2    ok ive seen enough whats going happen guys mcc...\n",
       "3    nobody wants report pennsylvania michigan didn...\n",
       "4    pleased announce given full support endorsemen...\n",
       "5    everyone asking recent presidential polls inac...\n",
       "6    guy named al schmidt philadelphia commissioner...\n",
       "7    fake pollsters abcwashingtonpost produced poss...\n",
       "8    andrew mccabe exposed today us senate totally ...\n",
       "9    dont care state youre computer voting system w...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words(word has no specific meaning eg: on, the)\n",
    "df_Trumptweets['tweet'] = df_Trumptweets['tweet'].apply(\n",
    "    lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df_Trumptweets['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#removing number\n",
    "df_Trumptweets['tweet'] = df_Trumptweets['tweet'].str.replace('\\d+', '')\n",
    "df_Trumptweets['tweet'].replace(' ', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in d:\\anaconda\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in d:\\anaconda\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: click in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: regex in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#download textblob package\n",
    "!pip install -U textblob \n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    report dominion deleted million trump vote nat...\n",
       "1    foxnews daytime rating completely collapsed we...\n",
       "2    ok ive seen enough whats going happen guy mcca...\n",
       "3    nobody want report pennsylvania michigan didnt...\n",
       "4    pleased announce given full support endorsemen...\n",
       "5    everyone asking recent presidential poll inacc...\n",
       "6    guy named al schmidt philadelphia commissioner...\n",
       "7    fake pollster abcwashingtonpost produced possi...\n",
       "8    andrew mccabe exposed today u senate totally d...\n",
       "9    dont care state youre computer voting system w...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "#converts the word into its root word\n",
    "df_Trumptweets['tweet'] = df_Trumptweets['tweet'].apply(\n",
    "    lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df_Trumptweets['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=' '.join(df_Trumptweets['tweet'])\n",
    "# join all title into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=string.split()\n",
    "#split the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs = pd.Series(lst) \n",
    "#store the splited word vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote          18\n",
       "election      17\n",
       "ballot        10\n",
       "state         10\n",
       "win           10\n",
       "              ..\n",
       "leadership     1\n",
       "matthew        1\n",
       "learned        1\n",
       "know           1\n",
       "tabulation     1\n",
       "Length: 468, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs.value_counts()\n",
    "#word count of each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote            18\n",
       "election        17\n",
       "ballot          10\n",
       "state           10\n",
       "win             10\n",
       "president        8\n",
       "vaccine          7\n",
       "u                7\n",
       "big              7\n",
       "pennsylvania     7\n",
       "trump            6\n",
       "allowed          6\n",
       "would            6\n",
       "legal            6\n",
       "republican       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs.value_counts()[:15] \n",
    "#show the top 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote            18\n",
       "election        17\n",
       "ballot          10\n",
       "state           10\n",
       "win             10\n",
       "president        8\n",
       "vaccine          7\n",
       "u                7\n",
       "big              7\n",
       "pennsylvania     7\n",
       "trump            6\n",
       "allowed          6\n",
       "would            6\n",
       "legal            6\n",
       "republican       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common words screening \n",
    "freq_common = pd.Series(' '.join(df_Trumptweets['tweet']).split()).value_counts()[:15]\n",
    "freq_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "andor                1\n",
       "perhaps              1\n",
       "abcwashingtonpost    1\n",
       "integrity            1\n",
       "stock                1\n",
       "schmidt              1\n",
       "progress             1\n",
       "produced             1\n",
       "seen                 1\n",
       "bad                  1\n",
       "leadership           1\n",
       "matthew              1\n",
       "learned              1\n",
       "know                 1\n",
       "tabulation           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rare words screening\n",
    "freq_rare = pd.Series(' '.join(\n",
    "    df_Trumptweets['tweet']).split()).value_counts()[-15:]\n",
    "freq_rare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vote</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>election</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>win</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>state</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ballot</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>president</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>vaccine</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>big</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pennsylvania</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>u</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>would</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>allowed</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>legal</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>senate</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words    tf\n",
       "1            vote  18.0\n",
       "27       election  17.0\n",
       "66            win  10.0\n",
       "8           state  10.0\n",
       "176        ballot  10.0\n",
       "15      president   8.0\n",
       "229       vaccine   7.0\n",
       "124           big   7.0\n",
       "6    pennsylvania   7.0\n",
       "93              u   7.0\n",
       "247         would   6.0\n",
       "77        allowed   6.0\n",
       "0           trump   6.0\n",
       "218         legal   6.0\n",
       "148        senate   5.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distinguishing Trump's tweets with others\n",
    "tf1 = df_Trumptweets['tweet'].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(\n",
    "    axis=0).reset_index()\n",
    "\n",
    "tf1.columns = ['words', 'tf']\n",
    "tf1.sort_values(['tf'], ascending=False).head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
