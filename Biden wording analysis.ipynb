{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analysis of Biden's tweets\n",
    "\n",
    "Stylometry: to find out the style of writing or frequency of words from Mr. Joe Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>comments</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326968002839908353</td>\n",
       "      <td>2020-11-12 19:20:00+00:00</td>\n",
       "      <td>I extend my deep condolences to the loved ones...</td>\n",
       "      <td>33000</td>\n",
       "      <td>5000</td>\n",
       "      <td>497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326557341697839106</td>\n",
       "      <td>2020-11-11 16:08:11+00:00</td>\n",
       "      <td>Today, we honor the service of those who have ...</td>\n",
       "      <td>8700</td>\n",
       "      <td>35000</td>\n",
       "      <td>363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326344141446373376</td>\n",
       "      <td>2020-11-11 02:01:00+00:00</td>\n",
       "      <td>We are going to build a health care system tha...</td>\n",
       "      <td>24700</td>\n",
       "      <td>4000</td>\n",
       "      <td>437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326306141056364544</td>\n",
       "      <td>2020-11-10 23:30:00+00:00</td>\n",
       "      <td>When I’m speaking to foreign leaders, I’m tell...</td>\n",
       "      <td>37700</td>\n",
       "      <td>16500</td>\n",
       "      <td>632200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326284750420643846</td>\n",
       "      <td>2020-11-10 22:05:00+00:00</td>\n",
       "      <td>Come January, we will work quickly with Congre...</td>\n",
       "      <td>12600</td>\n",
       "      <td>227000</td>\n",
       "      <td>305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326266378991542272</td>\n",
       "      <td>2020-11-10 20:52:00+00:00</td>\n",
       "      <td>Beginning on January 20th, Vice President-elec...</td>\n",
       "      <td>15500</td>\n",
       "      <td>33200</td>\n",
       "      <td>444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325890910635384839</td>\n",
       "      <td>2020-11-09 20:00:01+00:00</td>\n",
       "      <td>I won't be president until January 20th, but m...</td>\n",
       "      <td>161700</td>\n",
       "      <td>23900</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325885871875190784</td>\n",
       "      <td>2020-11-09 19:40:00+00:00</td>\n",
       "      <td>The bottom line: I will spare no effort to tur...</td>\n",
       "      <td>15900</td>\n",
       "      <td>29800</td>\n",
       "      <td>488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325880083618426881</td>\n",
       "      <td>2020-11-09 19:17:00+00:00</td>\n",
       "      <td>The challenge before us right now is still imm...</td>\n",
       "      <td>7700</td>\n",
       "      <td>14400</td>\n",
       "      <td>248300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325873288711712769</td>\n",
       "      <td>2020-11-09 18:50:00+00:00</td>\n",
       "      <td>My COVID-19 Transition Advisory Board will adv...</td>\n",
       "      <td>4500</td>\n",
       "      <td>14200</td>\n",
       "      <td>197700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325870017401905152</td>\n",
       "      <td>2020-11-09 18:37:00+00:00</td>\n",
       "      <td>Today, I have named a COVID-19 Transition Advi...</td>\n",
       "      <td>10500</td>\n",
       "      <td>29300</td>\n",
       "      <td>348200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325259242631274496</td>\n",
       "      <td>2020-11-08 02:10:00+00:00</td>\n",
       "      <td>A nation united. A nation strengthened. A nati...</td>\n",
       "      <td>40400</td>\n",
       "      <td>81400</td>\n",
       "      <td>937800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325258739318927361</td>\n",
       "      <td>2020-11-08 02:08:00+00:00</td>\n",
       "      <td>With full hearts and steady hands, with faith ...</td>\n",
       "      <td>15000</td>\n",
       "      <td>46700</td>\n",
       "      <td>634200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325257984562192385</td>\n",
       "      <td>2020-11-08 02:05:00+00:00</td>\n",
       "      <td>Tonight, the whole world is watching America. ...</td>\n",
       "      <td>8100</td>\n",
       "      <td>26600</td>\n",
       "      <td>344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325257229625421825</td>\n",
       "      <td>2020-11-08 02:02:00+00:00</td>\n",
       "      <td>Especially for those moments when this campaig...</td>\n",
       "      <td>8600</td>\n",
       "      <td>43900</td>\n",
       "      <td>483600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325256474415800322</td>\n",
       "      <td>2020-11-08 01:59:00+00:00</td>\n",
       "      <td>I believe that this is part of the mandate fro...</td>\n",
       "      <td>3800</td>\n",
       "      <td>8900</td>\n",
       "      <td>146200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325255719336243200</td>\n",
       "      <td>2020-11-08 01:56:00+00:00</td>\n",
       "      <td>Now that the campaign is over—what is the peop...</td>\n",
       "      <td>14500</td>\n",
       "      <td>20600</td>\n",
       "      <td>252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325254964415881216</td>\n",
       "      <td>2020-11-08 01:53:00+00:00</td>\n",
       "      <td>We cannot repair the economy, restore our vita...</td>\n",
       "      <td>9700</td>\n",
       "      <td>23800</td>\n",
       "      <td>294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325254461049073664</td>\n",
       "      <td>2020-11-08 01:51:00+00:00</td>\n",
       "      <td>The Bible tells us that to everything there is...</td>\n",
       "      <td>24500</td>\n",
       "      <td>47300</td>\n",
       "      <td>36400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325254209613123584</td>\n",
       "      <td>2020-11-08 01:50:00+00:00</td>\n",
       "      <td>It’s time to put away the harsh rhetoric. To l...</td>\n",
       "      <td>7200</td>\n",
       "      <td>21200</td>\n",
       "      <td>263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325253706061926401</td>\n",
       "      <td>2020-11-08 01:48:00+00:00</td>\n",
       "      <td>To all those who volunteered, worked the polls...</td>\n",
       "      <td>3200</td>\n",
       "      <td>13600</td>\n",
       "      <td>237100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325253454571270144</td>\n",
       "      <td>2020-11-08 01:47:00+00:00</td>\n",
       "      <td>For America’s educators, this is a great day: ...</td>\n",
       "      <td>9300</td>\n",
       "      <td>75300</td>\n",
       "      <td>711400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325253203022241792</td>\n",
       "      <td>2020-11-08 01:46:00+00:00</td>\n",
       "      <td>I pledge to be a President who seeks not to di...</td>\n",
       "      <td>32400</td>\n",
       "      <td>33700</td>\n",
       "      <td>43100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325252951124762625</td>\n",
       "      <td>2020-11-08 01:45:00+00:00</td>\n",
       "      <td>Folks, the people of this nation have spoken. ...</td>\n",
       "      <td>17900</td>\n",
       "      <td>20200</td>\n",
       "      <td>265700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fact</td>\n",
       "      <td>1324926298762870785</td>\n",
       "      <td>2020-11-07 04:07:00+00:00</td>\n",
       "      <td>We may be opponents — but we are not enemies. ...</td>\n",
       "      <td>32000</td>\n",
       "      <td>91300</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fact</td>\n",
       "      <td>1324925795991609348</td>\n",
       "      <td>2020-11-07 04:05:00+00:00</td>\n",
       "      <td>We have to remember the purpose of our politic...</td>\n",
       "      <td>11500</td>\n",
       "      <td>21000</td>\n",
       "      <td>370100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fact</td>\n",
       "      <td>1324925040660393987</td>\n",
       "      <td>2020-11-07 04:02:00+00:00</td>\n",
       "      <td>I know tensions can be high after a tough elec...</td>\n",
       "      <td>10000</td>\n",
       "      <td>20900</td>\n",
       "      <td>375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fact</td>\n",
       "      <td>1324924538749026306</td>\n",
       "      <td>2020-11-07 04:00:00+00:00</td>\n",
       "      <td>We are going to be the first Democrats to win ...</td>\n",
       "      <td>6300</td>\n",
       "      <td>25000</td>\n",
       "      <td>341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fact</td>\n",
       "      <td>1324924285631176704</td>\n",
       "      <td>2020-11-07 03:59:00+00:00</td>\n",
       "      <td>What is becoming clearer each hour is that rec...</td>\n",
       "      <td>5100</td>\n",
       "      <td>18900</td>\n",
       "      <td>224500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fact</td>\n",
       "      <td>1324923025138049027</td>\n",
       "      <td>2020-11-07 03:53:59+00:00</td>\n",
       "      <td>The numbers tell us a clear and convincing sto...</td>\n",
       "      <td>22100</td>\n",
       "      <td>57500</td>\n",
       "      <td>841800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                   id                       date  \\\n",
       "0   fact  1326968002839908353  2020-11-12 19:20:00+00:00   \n",
       "1   fact  1326557341697839106  2020-11-11 16:08:11+00:00   \n",
       "2   fact  1326344141446373376  2020-11-11 02:01:00+00:00   \n",
       "3   fact  1326306141056364544  2020-11-10 23:30:00+00:00   \n",
       "4   fact  1326284750420643846  2020-11-10 22:05:00+00:00   \n",
       "5   fact  1326266378991542272  2020-11-10 20:52:00+00:00   \n",
       "6   fact  1325890910635384839  2020-11-09 20:00:01+00:00   \n",
       "7   fact  1325885871875190784  2020-11-09 19:40:00+00:00   \n",
       "8   fact  1325880083618426881  2020-11-09 19:17:00+00:00   \n",
       "9   fact  1325873288711712769  2020-11-09 18:50:00+00:00   \n",
       "10  fact  1325870017401905152  2020-11-09 18:37:00+00:00   \n",
       "11  fact  1325259242631274496  2020-11-08 02:10:00+00:00   \n",
       "12  fact  1325258739318927361  2020-11-08 02:08:00+00:00   \n",
       "13  fact  1325257984562192385  2020-11-08 02:05:00+00:00   \n",
       "14  fact  1325257229625421825  2020-11-08 02:02:00+00:00   \n",
       "15  fact  1325256474415800322  2020-11-08 01:59:00+00:00   \n",
       "16  fact  1325255719336243200  2020-11-08 01:56:00+00:00   \n",
       "17  fact  1325254964415881216  2020-11-08 01:53:00+00:00   \n",
       "18  fact  1325254461049073664  2020-11-08 01:51:00+00:00   \n",
       "19  fact  1325254209613123584  2020-11-08 01:50:00+00:00   \n",
       "20  fact  1325253706061926401  2020-11-08 01:48:00+00:00   \n",
       "21  fact  1325253454571270144  2020-11-08 01:47:00+00:00   \n",
       "22  fact  1325253203022241792  2020-11-08 01:46:00+00:00   \n",
       "23  fact  1325252951124762625  2020-11-08 01:45:00+00:00   \n",
       "24  fact  1324926298762870785  2020-11-07 04:07:00+00:00   \n",
       "25  fact  1324925795991609348  2020-11-07 04:05:00+00:00   \n",
       "26  fact  1324925040660393987  2020-11-07 04:02:00+00:00   \n",
       "27  fact  1324924538749026306  2020-11-07 04:00:00+00:00   \n",
       "28  fact  1324924285631176704  2020-11-07 03:59:00+00:00   \n",
       "29  fact  1324923025138049027  2020-11-07 03:53:59+00:00   \n",
       "\n",
       "                                                tweet  comments  retweets  \\\n",
       "0   I extend my deep condolences to the loved ones...     33000      5000   \n",
       "1   Today, we honor the service of those who have ...      8700     35000   \n",
       "2   We are going to build a health care system tha...     24700      4000   \n",
       "3   When I’m speaking to foreign leaders, I’m tell...     37700     16500   \n",
       "4   Come January, we will work quickly with Congre...     12600    227000   \n",
       "5   Beginning on January 20th, Vice President-elec...     15500     33200   \n",
       "6   I won't be president until January 20th, but m...    161700     23900   \n",
       "7   The bottom line: I will spare no effort to tur...     15900     29800   \n",
       "8   The challenge before us right now is still imm...      7700     14400   \n",
       "9   My COVID-19 Transition Advisory Board will adv...      4500     14200   \n",
       "10  Today, I have named a COVID-19 Transition Advi...     10500     29300   \n",
       "11  A nation united. A nation strengthened. A nati...     40400     81400   \n",
       "12  With full hearts and steady hands, with faith ...     15000     46700   \n",
       "13  Tonight, the whole world is watching America. ...      8100     26600   \n",
       "14  Especially for those moments when this campaig...      8600     43900   \n",
       "15  I believe that this is part of the mandate fro...      3800      8900   \n",
       "16  Now that the campaign is over—what is the peop...     14500     20600   \n",
       "17  We cannot repair the economy, restore our vita...      9700     23800   \n",
       "18  The Bible tells us that to everything there is...     24500     47300   \n",
       "19  It’s time to put away the harsh rhetoric. To l...      7200     21200   \n",
       "20  To all those who volunteered, worked the polls...      3200     13600   \n",
       "21  For America’s educators, this is a great day: ...      9300     75300   \n",
       "22  I pledge to be a President who seeks not to di...     32400     33700   \n",
       "23  Folks, the people of this nation have spoken. ...     17900     20200   \n",
       "24  We may be opponents — but we are not enemies. ...     32000     91300   \n",
       "25  We have to remember the purpose of our politic...     11500     21000   \n",
       "26  I know tensions can be high after a tough elec...     10000     20900   \n",
       "27  We are going to be the first Democrats to win ...      6300     25000   \n",
       "28  What is becoming clearer each hour is that rec...      5100     18900   \n",
       "29  The numbers tell us a clear and convincing sto...     22100     57500   \n",
       "\n",
       "     likes  \n",
       "0   497000  \n",
       "1   363000  \n",
       "2   437000  \n",
       "3   632200  \n",
       "4   305300  \n",
       "5   444500  \n",
       "6    15000  \n",
       "7   488500  \n",
       "8   248300  \n",
       "9   197700  \n",
       "10  348200  \n",
       "11  937800  \n",
       "12  634200  \n",
       "13  344800  \n",
       "14  483600  \n",
       "15  146200  \n",
       "16  252500  \n",
       "17  294400  \n",
       "18   36400  \n",
       "19  263100  \n",
       "20  237100  \n",
       "21  711400  \n",
       "22   43100  \n",
       "23  265700  \n",
       "24   10000  \n",
       "25  370100  \n",
       "26  375600  \n",
       "27  341100  \n",
       "28  224500  \n",
       "29  841800  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data file we scraped from Donald Trump's twitter account\n",
    "df = pd.read_csv('Biden(processed).csv', encoding='utf8')\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame for the tweets\n",
    "df_Bidentweets = pd.DataFrame(df['tweet'], columns=[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I extend my deep condolences to the loved ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today, we honor the service of those who have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are going to build a health care system tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I’m speaking to foreign leaders, I’m tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Come January, we will work quickly with Congre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  I extend my deep condolences to the loved ones...\n",
       "1  Today, we honor the service of those who have ...\n",
       "2  We are going to build a health care system tha...\n",
       "3  When I’m speaking to foreign leaders, I’m tell...\n",
       "4  Come January, we will work quickly with Congre..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display first few\n",
    "df_Bidentweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I extend my deep condolences to the loved ones...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today, we honor the service of those who have ...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are going to build a health care system tha...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I’m speaking to foreign leaders, I’m tell...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Come January, we will work quickly with Congre...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  word_count\n",
       "0  I extend my deep condolences to the loved ones...          48\n",
       "1  Today, we honor the service of those who have ...          49\n",
       "2  We are going to build a health care system tha...          25\n",
       "3  When I’m speaking to foreign leaders, I’m tell...          23\n",
       "4  Come January, we will work quickly with Congre...          25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Bidentweets['word_count'] = df_Bidentweets['tweet'].apply(lambda x: len(str(x).split(\" \")))\n",
    "# count the word for each column\n",
    "df_Bidentweets[['tweet', 'word_count']].head()\n",
    "#[['titles', 'word_count']] is used to set the format of the table, the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing empty values if any\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i extend my deep condolences to the loved ones...\n",
       "1    today, we honor the service of those who have ...\n",
       "2    we are going to build a health care system tha...\n",
       "3    when i’m speaking to foreign leaders, i’m tell...\n",
       "4    come january, we will work quickly with congre...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the title, turn every word into lower case and join them together\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].apply(\n",
    "    lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "#display the first few\n",
    "df_Bidentweets['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i extend my deep condolences to the loved ones...\n",
       "1    today we honor the service of those who have w...\n",
       "2    we are going to build a health care system tha...\n",
       "3    when im speaking to foreign leaders im telling...\n",
       "4    come january we will work quickly with congres...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing punctuations\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].str.replace('[^\\w\\s]', '')\n",
    "df_Bidentweets['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#import the stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop\n",
    "#A list to know what are stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    extend deep condolences loved ones peacekeeper...\n",
       "1    today honor service worn uniform armed forces ...\n",
       "2    going build health care system puts family fir...\n",
       "3    im speaking foreign leaders im telling america...\n",
       "4    come january work quickly congress dramaticall...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words(word has no specific meaning eg: on, the)\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].apply(\n",
    "    lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df_Bidentweets['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#removing number\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].str.replace('\\d+', '')\n",
    "df_Bidentweets['tweet'].replace(' ', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in d:\\anaconda\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in d:\\anaconda\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: regex in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied, skipping upgrade: joblib in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: click in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob \n",
    "#download textblob package\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    extend deep condolence loved one peacekeeper i...\n",
       "1    today honor service worn uniform armed force u...\n",
       "2    going build health care system put family firs...\n",
       "3    im speaking foreign leader im telling america ...\n",
       "4    come january work quickly congress dramaticall...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "#converts the word into its root word\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].apply(\n",
    "    lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df_Bidentweets['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=' '.join(df_Bidentweets['tweet'])\n",
    "# join all title into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=string.split()\n",
    "#split the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs = pd.Series(lst) \n",
    "#store the splited word vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american    10\n",
       "going       10\n",
       "u           10\n",
       "america      9\n",
       "time         7\n",
       "            ..\n",
       "everyone     1\n",
       "georgia      1\n",
       "arizona      1\n",
       "record       1\n",
       "call         1\n",
       "Length: 296, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs.value_counts()\n",
    "#word count of each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american    10\n",
       "going       10\n",
       "u           10\n",
       "america      9\n",
       "time         7\n",
       "nation       6\n",
       "force        5\n",
       "health       5\n",
       "people       5\n",
       "care         5\n",
       "win          4\n",
       "covid        4\n",
       "first        4\n",
       "state        4\n",
       "one          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs.value_counts()[:15] \n",
    "#show the top 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american    10\n",
       "going       10\n",
       "u           10\n",
       "america      9\n",
       "time         7\n",
       "nation       6\n",
       "force        5\n",
       "health       5\n",
       "people       5\n",
       "care         5\n",
       "win          4\n",
       "covid        4\n",
       "first        4\n",
       "state        4\n",
       "one          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common words screening \n",
    "freq_common = pd.Series(' '.join(df_Bidentweets['tweet']).split()).value_counts()[:15]\n",
    "freq_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "empathy         1\n",
       "enemy           1\n",
       "detailed        1\n",
       "virus           1\n",
       "understands     1\n",
       "dramatically    1\n",
       "precious        1\n",
       "warfare         1\n",
       "want            1\n",
       "honor           1\n",
       "everyone        1\n",
       "georgia         1\n",
       "arizona         1\n",
       "record          1\n",
       "call            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rare words screening\n",
    "freq_rare = pd.Series(' '.join(\n",
    "    df_Bidentweets['tweet']).split()).value_counts()[-15:]\n",
    "freq_rare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>going</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>u</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>america</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>time</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>nation</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>health</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>care</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>force</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>people</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>united</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>state</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>covid</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>win</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words    tf\n",
       "0    american  10.0\n",
       "42      going  10.0\n",
       "94          u  10.0\n",
       "55    america   9.0\n",
       "181      time   7.0\n",
       "132    nation   6.0\n",
       "46     health   5.0\n",
       "49       care   5.0\n",
       "24      force   5.0\n",
       "170    people   5.0\n",
       "1         one   4.0\n",
       "35     united   4.0\n",
       "39      state   4.0\n",
       "107     covid   4.0\n",
       "236       win   4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distinguishing Biden's tweets with others\n",
    "tf2 = df_Bidentweets['tweet'].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(\n",
    "    axis=0).reset_index()\n",
    "\n",
    "tf2.columns = ['words', 'tf']\n",
    "tf2.sort_values(['tf'], ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
