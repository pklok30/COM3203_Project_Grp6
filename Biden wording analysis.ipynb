{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text analysis of Biden's tweets\n",
    "\n",
    "Stylometry: to find out the style of writing or frequency of words from Mr. Joe Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>comments</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326968002839908353</td>\n",
       "      <td>2020-11-12 19:20:00+00:00</td>\n",
       "      <td>I extend my deep condolences to the loved ones...</td>\n",
       "      <td>33000</td>\n",
       "      <td>5000</td>\n",
       "      <td>497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326557341697839106</td>\n",
       "      <td>2020-11-11 16:08:11+00:00</td>\n",
       "      <td>Today, we honor the service of those who have ...</td>\n",
       "      <td>8700</td>\n",
       "      <td>35000</td>\n",
       "      <td>363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326344141446373376</td>\n",
       "      <td>2020-11-11 02:01:00+00:00</td>\n",
       "      <td>We are going to build a health care system tha...</td>\n",
       "      <td>24700</td>\n",
       "      <td>4000</td>\n",
       "      <td>437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326306141056364544</td>\n",
       "      <td>2020-11-10 23:30:00+00:00</td>\n",
       "      <td>When I’m speaking to foreign leaders, I’m tell...</td>\n",
       "      <td>37700</td>\n",
       "      <td>16500</td>\n",
       "      <td>632200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326284750420643846</td>\n",
       "      <td>2020-11-10 22:05:00+00:00</td>\n",
       "      <td>Come January, we will work quickly with Congre...</td>\n",
       "      <td>12600</td>\n",
       "      <td>227000</td>\n",
       "      <td>305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fact</td>\n",
       "      <td>1326266378991542272</td>\n",
       "      <td>2020-11-10 20:52:00+00:00</td>\n",
       "      <td>Beginning on January 20th, Vice President-elec...</td>\n",
       "      <td>15500</td>\n",
       "      <td>33200</td>\n",
       "      <td>444500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325890910635384839</td>\n",
       "      <td>2020-11-09 20:00:01+00:00</td>\n",
       "      <td>I won't be president until January 20th, but m...</td>\n",
       "      <td>161700</td>\n",
       "      <td>23900</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325885871875190784</td>\n",
       "      <td>2020-11-09 19:40:00+00:00</td>\n",
       "      <td>The bottom line: I will spare no effort to tur...</td>\n",
       "      <td>15900</td>\n",
       "      <td>29800</td>\n",
       "      <td>488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325880083618426881</td>\n",
       "      <td>2020-11-09 19:17:00+00:00</td>\n",
       "      <td>The challenge before us right now is still imm...</td>\n",
       "      <td>7700</td>\n",
       "      <td>14400</td>\n",
       "      <td>248300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fact</td>\n",
       "      <td>1325873288711712769</td>\n",
       "      <td>2020-11-09 18:50:00+00:00</td>\n",
       "      <td>My COVID-19 Transition Advisory Board will adv...</td>\n",
       "      <td>4500</td>\n",
       "      <td>14200</td>\n",
       "      <td>197700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                   id                       date  \\\n",
       "0  fact  1326968002839908353  2020-11-12 19:20:00+00:00   \n",
       "1  fact  1326557341697839106  2020-11-11 16:08:11+00:00   \n",
       "2  fact  1326344141446373376  2020-11-11 02:01:00+00:00   \n",
       "3  fact  1326306141056364544  2020-11-10 23:30:00+00:00   \n",
       "4  fact  1326284750420643846  2020-11-10 22:05:00+00:00   \n",
       "5  fact  1326266378991542272  2020-11-10 20:52:00+00:00   \n",
       "6  fact  1325890910635384839  2020-11-09 20:00:01+00:00   \n",
       "7  fact  1325885871875190784  2020-11-09 19:40:00+00:00   \n",
       "8  fact  1325880083618426881  2020-11-09 19:17:00+00:00   \n",
       "9  fact  1325873288711712769  2020-11-09 18:50:00+00:00   \n",
       "\n",
       "                                               tweet  comments  retweets  \\\n",
       "0  I extend my deep condolences to the loved ones...     33000      5000   \n",
       "1  Today, we honor the service of those who have ...      8700     35000   \n",
       "2  We are going to build a health care system tha...     24700      4000   \n",
       "3  When I’m speaking to foreign leaders, I’m tell...     37700     16500   \n",
       "4  Come January, we will work quickly with Congre...     12600    227000   \n",
       "5  Beginning on January 20th, Vice President-elec...     15500     33200   \n",
       "6  I won't be president until January 20th, but m...    161700     23900   \n",
       "7  The bottom line: I will spare no effort to tur...     15900     29800   \n",
       "8  The challenge before us right now is still imm...      7700     14400   \n",
       "9  My COVID-19 Transition Advisory Board will adv...      4500     14200   \n",
       "\n",
       "    likes  \n",
       "0  497000  \n",
       "1  363000  \n",
       "2  437000  \n",
       "3  632200  \n",
       "4  305300  \n",
       "5  444500  \n",
       "6   15000  \n",
       "7  488500  \n",
       "8  248300  \n",
       "9  197700  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data file we scraped from Donald Trump's twitter account\n",
    "df = pd.read_csv('Biden(processed).csv', encoding='utf8')\n",
    "#display the first ten row\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame for the tweets\n",
    "df_Bidentweets = pd.DataFrame(df['tweet'], columns=[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I extend my deep condolences to the loved ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today, we honor the service of those who have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are going to build a health care system tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I’m speaking to foreign leaders, I’m tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Come January, we will work quickly with Congre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beginning on January 20th, Vice President-elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I won't be president until January 20th, but m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The bottom line: I will spare no effort to tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The challenge before us right now is still imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My COVID-19 Transition Advisory Board will adv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  I extend my deep condolences to the loved ones...\n",
       "1  Today, we honor the service of those who have ...\n",
       "2  We are going to build a health care system tha...\n",
       "3  When I’m speaking to foreign leaders, I’m tell...\n",
       "4  Come January, we will work quickly with Congre...\n",
       "5  Beginning on January 20th, Vice President-elec...\n",
       "6  I won't be president until January 20th, but m...\n",
       "7  The bottom line: I will spare no effort to tur...\n",
       "8  The challenge before us right now is still imm...\n",
       "9  My COVID-19 Transition Advisory Board will adv..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the first ten row\n",
    "df_Bidentweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I extend my deep condolences to the loved ones...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today, we honor the service of those who have ...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We are going to build a health care system tha...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When I’m speaking to foreign leaders, I’m tell...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Come January, we will work quickly with Congre...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beginning on January 20th, Vice President-elec...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I won't be president until January 20th, but m...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The bottom line: I will spare no effort to tur...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The challenge before us right now is still imm...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My COVID-19 Transition Advisory Board will adv...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  word_count\n",
       "0  I extend my deep condolences to the loved ones...          48\n",
       "1  Today, we honor the service of those who have ...          49\n",
       "2  We are going to build a health care system tha...          25\n",
       "3  When I’m speaking to foreign leaders, I’m tell...          23\n",
       "4  Come January, we will work quickly with Congre...          25\n",
       "5  Beginning on January 20th, Vice President-elec...          29\n",
       "6  I won't be president until January 20th, but m...          18\n",
       "7  The bottom line: I will spare no effort to tur...          13\n",
       "8  The challenge before us right now is still imm...          23\n",
       "9  My COVID-19 Transition Advisory Board will adv...          29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Bidentweets['word_count'] = df_Bidentweets['tweet'].apply(lambda x: len(str(x).split(\" \")))\n",
    "# count the word for each column\n",
    "df_Bidentweets[['tweet', 'word_count']].head(10)\n",
    "#[['titles', 'word_count']] is used to set the format of the table, the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing empty values if any\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i extend my deep condolences to the loved ones...\n",
       "1    today, we honor the service of those who have ...\n",
       "2    we are going to build a health care system tha...\n",
       "3    when i’m speaking to foreign leaders, i’m tell...\n",
       "4    come january, we will work quickly with congre...\n",
       "5    beginning on january 20th, vice president-elec...\n",
       "6    i won't be president until january 20th, but m...\n",
       "7    the bottom line: i will spare no effort to tur...\n",
       "8    the challenge before us right now is still imm...\n",
       "9    my covid-19 transition advisory board will adv...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the title, turn every word into lower case and join them together\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].apply(\n",
    "    lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "#display the first ten row\n",
    "df_Bidentweets['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i extend my deep condolences to the loved ones...\n",
       "1    today we honor the service of those who have w...\n",
       "2    we are going to build a health care system tha...\n",
       "3    when im speaking to foreign leaders im telling...\n",
       "4    come january we will work quickly with congres...\n",
       "5    beginning on january 20th vice presidentelect ...\n",
       "6    i wont be president until january 20th but my ...\n",
       "7    the bottom line i will spare no effort to turn...\n",
       "8    the challenge before us right now is still imm...\n",
       "9    my covid19 transition advisory board will advi...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing punctuations\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].str.replace('[^\\w\\s]', '')\n",
    "df_Bidentweets['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#import the stop words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop\n",
    "#A list to know what are stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    extend deep condolences loved ones peacekeeper...\n",
       "1    today honor service worn uniform armed forces ...\n",
       "2    going build health care system puts family fir...\n",
       "3    im speaking foreign leaders im telling america...\n",
       "4    come january work quickly congress dramaticall...\n",
       "5    beginning january 20th vice presidentelect har...\n",
       "6    wont president january 20th message today ever...\n",
       "7        bottom line spare effort turn pandemic around\n",
       "8    challenge us right still immense growing need ...\n",
       "9    covid19 transition advisory board advise detai...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words(word has no specific meaning eg: on, the)\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].apply(\n",
    "    lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df_Bidentweets['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#removing number\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].str.replace('\\d+', '')\n",
    "df_Bidentweets['tweet'].replace(' ', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in d:\\anaconda\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in d:\\anaconda\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: regex in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (2020.6.8)\n",
      "Requirement already satisfied, skipping upgrade: click in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in d:\\anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (4.47.0)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\pklok_gaming\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob \n",
    "#download textblob package\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    extend deep condolence loved one peacekeeper i...\n",
       "1    today honor service worn uniform armed force u...\n",
       "2    going build health care system put family firs...\n",
       "3    im speaking foreign leader im telling america ...\n",
       "4    come january work quickly congress dramaticall...\n",
       "5    beginning january th vice presidentelect harri...\n",
       "6    wont president january th message today everyo...\n",
       "7        bottom line spare effort turn pandemic around\n",
       "8    challenge u right still immense growing need b...\n",
       "9    covid transition advisory board advise detaile...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "#converts the word into its root word\n",
    "df_Bidentweets['tweet'] = df_Bidentweets['tweet'].apply(\n",
    "    lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df_Bidentweets['tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=' '.join(df_Bidentweets['tweet'])\n",
    "# join all title into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=string.split()\n",
    "#split the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs = pd.Series(lst) \n",
    "#store the splited word vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american          10\n",
       "u                 10\n",
       "going             10\n",
       "america            9\n",
       "time               7\n",
       "                  ..\n",
       "endured            1\n",
       "presidentelect     1\n",
       "purpose            1\n",
       "around             1\n",
       "matter             1\n",
       "Length: 296, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs.value_counts()\n",
    "#word count of each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american    10\n",
       "u           10\n",
       "going       10\n",
       "america      9\n",
       "time         7\n",
       "nation       6\n",
       "health       5\n",
       "people       5\n",
       "care         5\n",
       "force        5\n",
       "state        4\n",
       "first        4\n",
       "united       4\n",
       "covid        4\n",
       "one          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs.value_counts()[:15] \n",
    "#show the top 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "american    10\n",
       "u           10\n",
       "going       10\n",
       "america      9\n",
       "time         7\n",
       "nation       6\n",
       "health       5\n",
       "people       5\n",
       "care         5\n",
       "force        5\n",
       "state        4\n",
       "first        4\n",
       "united       4\n",
       "covid        4\n",
       "one          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common words screening \n",
    "freq_common = pd.Series(' '.join(df_Bidentweets['tweet']).split()).value_counts()[:15]\n",
    "freq_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "like              1\n",
       "died              1\n",
       "rhetoric          1\n",
       "detailed          1\n",
       "never             1\n",
       "stood             1\n",
       "cost              1\n",
       "story             1\n",
       "challenge         1\n",
       "arizona           1\n",
       "endured           1\n",
       "presidentelect    1\n",
       "purpose           1\n",
       "around            1\n",
       "matter            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rare words screening\n",
    "freq_rare = pd.Series(' '.join(\n",
    "    df_Bidentweets['tweet']).split()).value_counts()[-15:]\n",
    "freq_rare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>going</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>u</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>america</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>time</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>nation</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>people</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>force</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>care</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>health</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>win</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>united</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>state</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>first</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words    tf\n",
       "0    american  10.0\n",
       "47      going  10.0\n",
       "94          u  10.0\n",
       "53    america   9.0\n",
       "181      time   7.0\n",
       "132    nation   6.0\n",
       "175    people   5.0\n",
       "30      force   5.0\n",
       "46       care   5.0\n",
       "50     health   5.0\n",
       "235       win   4.0\n",
       "29     united   4.0\n",
       "26      state   4.0\n",
       "2         one   4.0\n",
       "43      first   4.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distinguishing Biden's tweets with others\n",
    "tf2 = df_Bidentweets['tweet'].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(\n",
    "    axis=0).reset_index()\n",
    "\n",
    "tf2.columns = ['words', 'tf']\n",
    "tf2.sort_values(['tf'], ascending=False).head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
